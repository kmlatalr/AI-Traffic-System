ðŸš‘ AI-Powered Smart Traffic Management System for Emergency Vehicles

Acknowledgement: This project is supported by TÃœBÄ°TAK (The Scientific and Technological Research Council of TÃ¼rkiye) under the 2209-A University Students Research Projects Support Program.

ðŸ“– Project Abstract

This research project aims to minimize the response time of emergency vehicles (ambulances) in heavy traffic. We developed a Hybrid Detection System prototype running on a Raspberry Pi 5 that combines Acoustic Signal Processing and Computer Vision.

Unlike traditional systems that rely solely on cameras (which fail in blind spots) or GPS (which has latency), our system utilizes MFCC (Mel-Frequency Cepstral Coefficients) features to detect siren sounds and verifies them with visual object detection to dynamically control traffic lights.

âš™ï¸ System Architecture (Sensor Fusion)

The core innovation of this project is the Data Fusion of audio and visual inputs to prevent false positives.

graph TD
    subgraph "Sensory Input Layer"
        Mic[Acoustic Sensors] -->|Raw Audio Stream| PreProcess[Noise Cancellation & Normalization]
        Cam[Camera Feed] -->|Video Stream| VisionInput[Frame Capture]
    end

    subgraph "Processing Unit (Raspberry Pi 5)"
        PreProcess -->|Extract Features| MFCC[MFCC Feature Extraction]
        MFCC -->|Input| AudioAI[Audio CNN Model]
        
        VisionInput -->|Input| YOLO[Object Detection Model (TensorFlow)]
        
        AudioAI -- "Siren Detected? (Probability > 0.8)" --> FusionEngine{Decision Fusion Engine}
        YOLO -- "Ambulance Visual Confirmed?" --> FusionEngine
    end

    subgraph "Actuation Layer"
        FusionEngine -->|YES: Priority Mode| Controller[Traffic Light Controller]
        Controller -->|Switch to Green| TrafficLights[Physical Traffic Lights]
        FusionEngine -->|NO: Standard Cycle| Standard[Normal Traffic Flow]
    end


ðŸ› ï¸ Technology Stack & Methods

ðŸ§  Artificial Intelligence & Signal Processing

Audio Processing: Librosa for extracting MFCC features from raw audio waves.

Deep Learning (Audio): Custom Convolutional Neural Network (CNN) trained on siren vs. noise datasets using TensorFlow/Keras.

Computer Vision: OpenCV and TensorFlow Lite for real-time vehicle classification.

Data Fusion: Custom algorithm to weight audio and video probabilities for final decision making.

hardware

Core Unit: Raspberry Pi 5 (Selected for high processing power for concurrent AI models).

Sensors: High-fidelity USB Microphones (for acoustic pickup).

Vision: Raspberry Pi Camera Module / USB Webcam.

ðŸ”¬ Methodology Details

1. Acoustic Detection (The "Ear")

We don't just look for loud noises; we look for the specific signature of a siren.

Feature Extraction: We use Mel-Frequency Cepstral Coefficients (MFCC) to convert audio waves into a visual representation (spectrogram) that the AI can understand.

Noise Filtering: Applied spectral gating to remove environmental city noise (horns, wind).

2. Visual Verification (The "Eye")

Once a potential siren is heard, the vision module activates to confirm the presence of an emergency vehicle, saving computational power and preventing false alarms from other loud sources.

ðŸ“Š Key Goals & Metrics

Accuracy: Target >95% accuracy in siren classification.

Latency: Inference time <1 second on edge hardware.

Impact: Estimated 20% reduction in ambulance travel time through busy intersections.

ðŸ“‚ Project Structure

AI_Traffic_System/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ audio/          # Raw audio samples (Siren/Noise)
â”‚   â”œâ”€â”€ features/       # Extracted MFCC features (.npy files)
â”‚   â””â”€â”€ models/         # Trained .h5 and .tflite models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sound_detector.py   # Audio processing & inference logic
â”‚   â”œâ”€â”€ vision_detector.py  # Object detection logic
â”‚   â””â”€â”€ traffic_control.py  # GPIO control for traffic lights
â”œâ”€â”€ notebooks/          # Jupyter notebooks for model training
â”œâ”€â”€ requirements.txt    # Dependencies (librosa, tensorflow, opencv-python)
â””â”€â”€ main.py             # Main execution loop


ðŸ‘¥ Team

Developers: Kemal Atalar, Beyza Kuzu

Supervisor: DoÃ§. Dr. Ferhat UÃ§ar

Institution: FÄ±rat University, Software Engineering Department

This project is part of the undergraduate research curriculum.
